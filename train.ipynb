{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgBdCKICMyyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8581e63-bfcb-4cc0-db48-9b3d02e899c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "all_stopwords = stopwords.words('english')\n",
        "all_stopwords.remove('not')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/datasset/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/datasset/test.csv')"
      ],
      "metadata": {
        "id": "7whrr4opM3-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().any(),test.isnull().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rksEYtMPIbf",
        "outputId": "fc00d2d3-fd8d-491e-89de-5c5888f0a236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(id               False\n",
              " comment_text     False\n",
              " toxic            False\n",
              " severe_toxic     False\n",
              " obscene          False\n",
              " threat           False\n",
              " insult           False\n",
              " identity_hate    False\n",
              " dtype: bool, id              False\n",
              " comment_text    False\n",
              " dtype: bool)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "y = train[list_classes].values\n",
        "list_sentences_train = train[\"comment_text\"]\n",
        "list_sentences_test = test[\"comment_text\"]\n",
        "\n",
        "print(list_sentences_train[0])"
      ],
      "metadata": {
        "id": "u8AjsSMKPir-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57ed65c-2b23-48a2-d17e-34ab7bf4f105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation\n",
            "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train=[]\n",
        "data_test=[]\n",
        "for string in list_sentences_train: \n",
        "  l = re.sub('[^a-zA-Z]',' ', string)\n",
        "  l = l.lower()\n",
        "  l = l.split()\n",
        "  l = [word for word in l if not word in set(all_stopwords)]\n",
        "  l = ' '.join(l)\n",
        "  data_train.append(l)\n",
        "\n",
        "for string in list_sentences_test:\n",
        "  ll = re.sub('[^a-zA-Z]',\" \", string)\n",
        "  ll = l.lower()\n",
        "  ll = l.split()\n",
        "  ll = [word for word in ll if not word in set(all_stopwords)]\n",
        "  ll = ' '.join(ll)\n",
        "  data_test.append(ll)\n",
        "\n",
        "print(data_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1NMufYiN-bT",
        "outputId": "ffaa5bbc-20db-4535-a06d-dcf187be3cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "explanation edits made username hardcore metallica fan reverted vandalisms closure gas voted new york dolls fac please remove template talk page since retired\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
      ],
      "metadata": {
        "id": "P3CkNDRJPlnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_tokenized_train[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCyWMh-3PwRm",
        "outputId": "162c1f92-0b91-4168-b172-53e84cc907da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[688,\n",
              "  75,\n",
              "  1,\n",
              "  126,\n",
              "  130,\n",
              "  177,\n",
              "  29,\n",
              "  672,\n",
              "  4511,\n",
              "  12052,\n",
              "  1116,\n",
              "  86,\n",
              "  331,\n",
              "  51,\n",
              "  2278,\n",
              "  11448,\n",
              "  50,\n",
              "  6864,\n",
              "  15,\n",
              "  60,\n",
              "  2756,\n",
              "  148,\n",
              "  7,\n",
              "  2937,\n",
              "  34,\n",
              "  117,\n",
              "  1221,\n",
              "  15190,\n",
              "  2825,\n",
              "  4,\n",
              "  45,\n",
              "  59,\n",
              "  244,\n",
              "  1,\n",
              "  365,\n",
              "  31,\n",
              "  1,\n",
              "  38,\n",
              "  27,\n",
              "  143,\n",
              "  73,\n",
              "  3462,\n",
              "  89,\n",
              "  3085,\n",
              "  4583,\n",
              "  2273,\n",
              "  985]]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 200\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "iom01jAMPxyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(maxlen, ))"
      ],
      "metadata": {
        "id": "WyodLrYWP52l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 128\n",
        "x = Embedding(max_features, embed_size)(inp)\n",
        "x = LSTM(60, return_sequences=True,name='lstm_layer')(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(50, activation=\"relu\")(x)\n",
        "x = Dense(6, activation=\"sigmoid\")(x)\n"
      ],
      "metadata": {
        "id": "OeAv4ZiVP_JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8ISgXonGQCUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 1\n",
        "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5VuCsuJQRAX",
        "outputId": "0dfda60f-c365-41d0-d3f3-e7698584b582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 787s 175ms/step - loss: 0.0400 - accuracy: 0.9704 - val_loss: 0.0474 - val_accuracy: 0.9914\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 784s 175ms/step - loss: 0.0352 - accuracy: 0.9317 - val_loss: 0.0494 - val_accuracy: 0.9854\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f25bc172410>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/datasset/mymodel')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7uzihxsTYEj",
        "outputId": "ef12d5b6-e4fb-4df7-aa51-2862a324bd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/datasset/mymodel/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/datasset/mymodel/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f25c60bc450> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    }
  ]
}